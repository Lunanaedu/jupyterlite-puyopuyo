{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step13 Animation　next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13 どういう風に動いているか、アニメーションで見たいよね\n",
    "\n",
    " step12 で学習したAgentで何かが動いています。どうなっているのかみたいですね。\n",
    " 公式を改造して、見れるようにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1 agent learned package\n",
    "\n",
    "puyopuyo-aiフォルダーと同じレベルにpuyopuyo-masterフォルダーがあります。puyopuyo-masterフォルダーにagent_package,agent,mod_srcフォルダーを作ります。agentフォルダーには、dezero_emb.pyをコピーします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agent_package', 'css', 'img', 'index.html', 'index_mod.html', 'README.me', 'src']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "agent_pkg_folder_name = '../puyopuyo-master/agent_learned_package'\n",
    "\n",
    "if not os.path.isdir(agent_pkg_folder_name):\n",
    "    os.mkdir(agent_pkg_folder_name)\n",
    "    shutil.copy( 'dezero_emb.py',agent_pkg_folder_name)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2 agent.py\n",
    "学習済みagentです。\n",
    "* 出力 : xの位置　、　回転0,90,180,270\n",
    "* 入力 : list board. puyo_color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../puyopuyo-master/agent_learned_package/agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $agent_pkg_folder_name/agent.py\n",
    "import numpy as np\n",
    "import random\n",
    "from puyopuyo import *\n",
    "import dezero_emb as dezero\n",
    "\n",
    "class DQNet(dezero.Models.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.l1 = dezero.L.Linear(128)\n",
    "    self.l2 = dezero.L.Linear(128)\n",
    "    self.l3 = dezero.L.Linear(1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = dezero.F.relu(self.l1(x))\n",
    "    x = dezero.F.relu(self.l2(x))\n",
    "    x = self.l3(x)\n",
    "    return x\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.action_size = 2\n",
    "        self.qnet = DQNet()\n",
    "\n",
    "    def __call__(self, board_list, puyo_c):\n",
    "        board_list = board_list.to_py()\n",
    "        board = np.zeros(CFG.Height * CFG.Width, dtype=np.int32).reshape(CFG.Height, CFG.Width)\n",
    "        for i in range(CFG.Height):\n",
    "            for j in range(CFG.Width):\n",
    "                if board_list[i][j] != None:\n",
    "                    board[i][j] = int(board_list[i][j]['puyo']) \n",
    "        puyo = Puyopuyo()\n",
    "        puyo.centerPuyo = puyo_c[0]\n",
    "        puyo.movablePuyo = puyo_c[1]\n",
    "\n",
    "        action = self.learned_agent(board, puyo)\n",
    "        action[1] = action[1] * 90\n",
    "        return action\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def learned_agent(self, board, puyo):\n",
    "        action_list = utils.create_action_list(board)\n",
    "        next_boards = []\n",
    "        next_reward =[]\n",
    "        action =(2, 1)\n",
    "        if len(action_list):\n",
    "            for action in action_list:\n",
    "                next_board, reward, done = utils.next_board(board, puyo, action)\n",
    "                if not done:\n",
    "                    next_boards.append(next_board)\n",
    "                    next_reward.append(reward)\n",
    "        \n",
    "        next_boards = np.stack(next_boards)\n",
    "        predictions = self.eval2(next_boards)\n",
    "        \n",
    "        next_reward =np.array(next_reward)[:, np.newaxis]\n",
    "        predictions += dezero.Variable(next_reward)\n",
    "        index = predictions.data.argmax()\n",
    "        action = action_list[index]\n",
    "        return action\n",
    "\n",
    "    def boardtostate(self, board):\n",
    "        cont_b = 2 ** np.arange(CFG.Width,dtype=np.int32)\n",
    "        b1 = np.zeros(CFG.Height * CFG.Width,dtype = np.int32).reshape(CFG.Height , CFG.Width)\n",
    "        b1[board == 1] = 1\n",
    "        b2 = np.zeros(CFG.Height * CFG.Width,dtype = np.int32).reshape(CFG.Height , CFG.Width)\n",
    "        b2[board == 2] = 1\n",
    "        b3 = np.zeros(CFG.Height * CFG.Width,dtype = np.int32).reshape(CFG.Height , CFG.Width)\n",
    "        b3[board == 3] = 1\n",
    "        b4 = np.zeros(CFG.Height * CFG.Width,dtype = np.int32).reshape(CFG.Height , CFG.Width)\n",
    "        b4[board == 4] = 1\n",
    "        board_list =np.concatenate([b1,b2,b3,b4])\n",
    "        state =  board_list.dot(cont_b)      \n",
    "        return state\n",
    "\n",
    "    def eval(self, board):\n",
    "        state = self.boardtostate(board)      \n",
    "        return self.qnet(state)\n",
    "\n",
    "    def eval2(self, boards):\n",
    "        states = []\n",
    "        for i in range(boards.shape[0]):\n",
    "            state = self.boardtostate(boards[i])\n",
    "            states.append(state)\n",
    "        states = np.stack(states)      \n",
    "        return self.qnet(states)\n",
    "\n",
    "    def load_model(self,filename):\n",
    "        self.qnet.load_weights(filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.3 init\n",
    "\n",
    "__init__.jsを入れます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../puyopuyo-master/agent_learned_package/__init__.js\n"
     ]
    }
   ],
   "source": [
    "%%writefile $agent_pkg_folder_name/__init__.js\n",
    "create_action = pyodide.runPython(`\n",
    "    from agent import *\n",
    "    agent = DQNAgent()\n",
    "    agent.load_model('puyopuyo.npz')\n",
    "    agent`);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../puyopuyo-master/agent_learned_package\\\\puyopuyo.npz'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy(\"puyopuyo.py\",agent_pkg_folder_name)\n",
    "shutil.copy(\"trained_models/puyopuyo.npz\",agent_pkg_folder_name)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.3　zipファイルを作ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\fgtoh\\\\Documents\\\\puyopuyo-py\\\\jupyterlite\\\\draft\\\\content\\\\puyopuyo-ai\\\\agent_learned.zip'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "shutil.make_archive('agent_learned', format='zip', root_dir=agent_pkg_folder_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
