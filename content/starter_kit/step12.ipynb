{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step12 learned Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 賢いagent作ってみましょう\n",
    "\n",
    "機械学習したモデルを使って、agentを作ります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは、基本的な部分を作っていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import dezero_emb as dezero\n",
    "from puyopuyo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dezero_embは、機械学習のためのフレームワークです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = \"trained_models/puyopuyo.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep_q_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNet(dezero.Models.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.l1 = dezero.L.Linear(128)\n",
    "    self.l2 = dezero.L.Linear(128)\n",
    "    self.l3 = dezero.L.Linear(1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = dezero.F.relu(self.l1(x))\n",
    "    x = dezero.F.relu(self.l2(x))\n",
    "    x = self.l3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "  def __init__(self):\n",
    "    self.action_size = 2\n",
    "    self.qnet = DQNet()\n",
    "\n",
    "  def __call__(self, board, puyo):\n",
    "    action_list = utils.create_action_list(board)\n",
    "    next_boards = []\n",
    "    next_reward =[]\n",
    "    action =(2, 1)\n",
    "    if len(action_list):\n",
    "      for action in action_list:\n",
    "        next_board, reward, done = utils.next_board(board, puyo, action)\n",
    "        if not done:\n",
    "          next_boards.append(next_board)\n",
    "          next_reward.append(reward)\n",
    "      \n",
    "      next_boards = np.stack(next_boards)\n",
    "      predictions = self.eval2(next_boards)\n",
    "      \n",
    "      next_reward =np.array(next_reward)[:, np.newaxis]\n",
    "      predictions += dezero.Variable(next_reward)\n",
    "      index = predictions.data.argmax()\n",
    "      action = action_list[index]\n",
    "    return action\n",
    "\n",
    "  def boardtostate(self, board):\n",
    "    cont_b = 2 ** np.arange(CFG.Width,dtype=np.int32)\n",
    "    b1 = np.zeros(CFG.Height * CFG.Width,dtype = np.int32).reshape(CFG.Height , CFG.Width)\n",
    "    b1[board == 1] = 1\n",
    "    b2 = np.zeros(CFG.Height * CFG.Width,dtype = np.int32).reshape(CFG.Height , CFG.Width)\n",
    "    b2[board == 2] = 1\n",
    "    b3 = np.zeros(CFG.Height * CFG.Width,dtype = np.int32).reshape(CFG.Height , CFG.Width)\n",
    "    b3[board == 3] = 1\n",
    "    b4 = np.zeros(CFG.Height * CFG.Width,dtype = np.int32).reshape(CFG.Height , CFG.Width)\n",
    "    b4[board == 4] = 1\n",
    "    board_list =np.concatenate([b1,b2,b3,b4])\n",
    "    state =  board_list.dot(cont_b)      \n",
    "    return state\n",
    "\n",
    "  def eval(self, board):\n",
    "    state = self.boardtostate(board)      \n",
    "    return self.qnet(state)\n",
    "\n",
    "  def eval2(self, boards):\n",
    "    states = []\n",
    "    for i in range(boards.shape[0]):\n",
    "      state = self.boardtostate(boards[i])\n",
    "      states.append(state)\n",
    "    states = np.stack(states)      \n",
    "    return self.qnet(states)\n",
    "\n",
    "  def load_model(self,filename):\n",
    "    self.qnet.load_weights(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 685590, pieces 3442\n",
      "Score: 51000, pieces 356\n",
      "Score: 597730, pieces 2988\n",
      "Score: 59470, pieces 496\n",
      "Score: 60920, pieces 432\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=123)\n",
    "env = EnvPuyopuyo()\n",
    "agent = DQNAgent()\n",
    "agent.load_model(model_filename)\n",
    "\n",
    "\n",
    "for _ in range(5):\n",
    "  board, puyo = env.reset()\n",
    "  done = False\n",
    "  final_score = 0\n",
    "  final_pieces = 0\n",
    "  while not done:\n",
    "    action = agent(board, puyo)\n",
    "    board, puyo, reward, done = env.step(action)\n",
    "    final_score += reward\n",
    "    final_pieces += 2\n",
    "\n",
    "  print(\"Score: {}, pieces {}\".format(\n",
    "    final_score,\n",
    "    final_pieces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まあまあ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
